---
name: Stuart Geiger
email: sgeiger@ucsd.edu
photo: https://datascience.ucsd.edu/wp-content/uploads/2022/09/Stuart-Geiger-1.jpg
website: https://stuartgeiger.com
domain: A14
title: Auditing Opaque Algorithmic Systems for Discrimination and Bias
bio: "I‚Äôm an social scientist with a background in the humanities, especially history and philosophy of science and technology, but I have enough expertise in computer science and data science to make trouble. I believe that data science systems should be fair, transparent, and accountable to the public, but that most are currently not. A lot of my research is in content moderation NLP systems for user-generated content, especially Wikipedia, where I formerly worked on their ML models and systems. "
description: "This group is for students interested in empirically investigating the outputs of real-world algorithmic systems for bias, discrimination, and other social issues --- particularly those where the code and/or training data are not publicly available. Do facial recognition classifiers work equally well on all kinds of faces? Does a job candidate's demographics impact which jobs they are recommended on a job search site? When you ask a generative image model to create images of a data scientist, what is the distribution by demographics?
<br>
We will study classic audits of non-algorithmic decision systems (e.g. equal opportunity hiring investigations in the 1970s) and contemporary audits of real-world ML/AI systems. We will learn various approaches to investigate such opaque systems, including auditing via synthetic training datasets, user reports, API scraping, fake/sockpuppet accounts, and headless browsers (where you programmatically control a web browser). We will also learn and discuss the legal and ethical issues around this kind of auditing, particularly around violating a platform's terms and conditions, which are complex. All students must take and pass the UCSD/CITI IRB Human Subject Protection Training online course (Social and Behavioral Basic) by week 3 of Fall, as well as submit their proposed Winter projects to the UCSD Institutional Review Board for legal and ethical review. For a selection of readings on this topic, see a past syllabus for a related graduate course: <a href='https://auditlab.stuartgeiger.com'>https://auditlab.stuartgeiger.com</a>"
summer: "Most important: identify potential algorithmic systems to audit for discrimination
<br>
Must take CITI IRB course by week 3 of Fall, about 2-3 hours, so get it done early if you can. Register at <a href='https://citiprogram.org'>https://citiprogram.org</a> (video of me registering, because the options are complex: <a href='https://www.youtube.com/watch?v=hOAgfK93QXg'>https://www.youtube.com/watch?v=hOAgfK93QXg</a>)
<br>
Our main textbooks that give overviews of this work, with examples of audits and methods: 
<ul><li>Auditing Algorithms by Metaxa et al (UCSD VPN required: <a href='https://www.nowpublishers.com/article/Details/HCI-083'>https://www.nowpublishers.com/article/Details/HCI-083</a>)</li>
<li>Fairness & Machine Learning by Barocas et al, especially Chapters 6+7 (<a href='https://fairmlbook.org/'>https://fairmlbook.org/</a>) </li>
</ul>

Other readings and examples: https://auditlab.stuartgeiger.com"
oldstudent: https://brianjhuang.github.io/CryptoWho/
prerequisites: None
time: Monday 12-1PM, In-Person üìç HDSI 138
style: I will be the only point of contact. Students will be expected to propose their own project auditing an existing algorithmic system of their own choosing, collect data through methods like headless browsers, and analyze data. I will help with ideas and details. 
seats: 4
tag: Causal Inference and Fairness
---